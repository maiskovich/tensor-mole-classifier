{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run for lr_1E-04conv2fc2\n",
      "Reading training images\n",
      "Loading benign files (Index: 0)\n",
      "Loading malignant files (Index: 1)\n",
      "Size of:\n",
      "- Training-set:\t\t1894\n",
      "- Validation-set:\t811\n",
      "Epoch 1 --- Training Accuracy:  35.0%, Validation Accuracy:  32.5%, Validation Loss: 14.998\n",
      "Epoch 2 --- Training Accuracy:  75.0%, Validation Accuracy:  75.0%, Validation Loss: 0.645\n",
      "Epoch 3 --- Training Accuracy:  72.5%, Validation Accuracy:  77.5%, Validation Loss: 0.470\n",
      "Epoch 4 --- Training Accuracy:  70.0%, Validation Accuracy:  70.0%, Validation Loss: 0.795\n",
      "Epoch 5 --- Training Accuracy:  72.5%, Validation Accuracy:  85.0%, Validation Loss: 0.536\n",
      "Epoch 6 --- Training Accuracy:  80.0%, Validation Accuracy:  70.0%, Validation Loss: 0.743\n",
      "Epoch 7 --- Training Accuracy:  87.5%, Validation Accuracy:  62.5%, Validation Loss: 0.879\n",
      "Epoch 8 --- Training Accuracy:  85.0%, Validation Accuracy:  70.0%, Validation Loss: 0.617\n",
      "Epoch 9 --- Training Accuracy:  72.5%, Validation Accuracy:  57.5%, Validation Loss: 0.978\n",
      "Epoch 10 --- Training Accuracy:  77.5%, Validation Accuracy:  75.0%, Validation Loss: 0.600\n",
      "Epoch 11 --- Training Accuracy:  80.0%, Validation Accuracy:  70.0%, Validation Loss: 0.676\n",
      "Epoch 12 --- Training Accuracy:  77.5%, Validation Accuracy:  80.0%, Validation Loss: 0.710\n",
      "Epoch 13 --- Training Accuracy:  85.0%, Validation Accuracy:  77.5%, Validation Loss: 0.610\n",
      "Epoch 14 --- Training Accuracy:  82.5%, Validation Accuracy:  67.5%, Validation Loss: 0.756\n",
      "Epoch 15 --- Training Accuracy:  90.0%, Validation Accuracy:  75.0%, Validation Loss: 0.569\n",
      "Epoch 16 --- Training Accuracy:  90.0%, Validation Accuracy:  72.5%, Validation Loss: 0.748\n",
      "Epoch 17 --- Training Accuracy:  92.5%, Validation Accuracy:  70.0%, Validation Loss: 0.512\n",
      "Epoch 18 --- Training Accuracy:  90.0%, Validation Accuracy:  85.0%, Validation Loss: 0.400\n",
      "Epoch 19 --- Training Accuracy:  75.0%, Validation Accuracy:  67.5%, Validation Loss: 0.894\n",
      "Epoch 20 --- Training Accuracy:  85.0%, Validation Accuracy:  67.5%, Validation Loss: 0.909\n",
      "Epoch 21 --- Training Accuracy:  97.5%, Validation Accuracy:  62.5%, Validation Loss: 0.760\n",
      "Epoch 22 --- Training Accuracy:  97.5%, Validation Accuracy:  82.5%, Validation Loss: 0.430\n",
      "Epoch 23 --- Training Accuracy:  97.5%, Validation Accuracy:  75.0%, Validation Loss: 0.552\n",
      "Epoch 24 --- Training Accuracy:  97.5%, Validation Accuracy:  80.0%, Validation Loss: 0.543\n",
      "Epoch 25 --- Training Accuracy:  97.5%, Validation Accuracy:  72.5%, Validation Loss: 0.585\n",
      "Epoch 26 --- Training Accuracy: 100.0%, Validation Accuracy:  57.5%, Validation Loss: 0.870\n",
      "Epoch 27 --- Training Accuracy: 100.0%, Validation Accuracy:  55.0%, Validation Loss: 0.922\n",
      "Epoch 28 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 0.775\n",
      "Epoch 29 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 0.894\n",
      "Epoch 30 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 0.571\n",
      "Epoch 31 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 0.712\n",
      "Epoch 32 --- Training Accuracy: 100.0%, Validation Accuracy:  85.0%, Validation Loss: 0.535\n",
      "Epoch 33 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 0.696\n",
      "Epoch 34 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 0.989\n",
      "Epoch 35 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.901\n",
      "Epoch 36 --- Training Accuracy: 100.0%, Validation Accuracy:  65.0%, Validation Loss: 0.845\n",
      "Epoch 37 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.722\n",
      "Epoch 38 --- Training Accuracy: 100.0%, Validation Accuracy:  80.0%, Validation Loss: 0.431\n",
      "Epoch 39 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 0.882\n",
      "Epoch 40 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.790\n",
      "Epoch 41 --- Training Accuracy: 100.0%, Validation Accuracy:  52.5%, Validation Loss: 0.997\n",
      "Epoch 42 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 0.588\n",
      "Epoch 43 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 0.654\n",
      "Epoch 44 --- Training Accuracy:  92.5%, Validation Accuracy:  80.0%, Validation Loss: 0.623\n",
      "Epoch 45 --- Training Accuracy:  85.0%, Validation Accuracy:  80.0%, Validation Loss: 0.852\n",
      "Epoch 46 --- Training Accuracy:  92.5%, Validation Accuracy:  80.0%, Validation Loss: 0.840\n",
      "Epoch 47 --- Training Accuracy:  95.0%, Validation Accuracy:  70.0%, Validation Loss: 1.362\n",
      "Epoch 48 --- Training Accuracy:  90.0%, Validation Accuracy:  77.5%, Validation Loss: 0.958\n",
      "Epoch 49 --- Training Accuracy:  87.5%, Validation Accuracy:  77.5%, Validation Loss: 1.112\n",
      "Epoch 50 --- Training Accuracy:  90.0%, Validation Accuracy:  72.5%, Validation Loss: 1.284\n",
      "Epoch 51 --- Training Accuracy:  95.0%, Validation Accuracy:  67.5%, Validation Loss: 1.199\n",
      "Epoch 52 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 1.043\n",
      "Epoch 53 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 0.968\n",
      "Epoch 54 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 1.235\n",
      "Epoch 55 --- Training Accuracy: 100.0%, Validation Accuracy:  80.0%, Validation Loss: 1.122\n",
      "Epoch 56 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 1.114\n",
      "Epoch 57 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.371\n",
      "Epoch 58 --- Training Accuracy: 100.0%, Validation Accuracy:  85.0%, Validation Loss: 0.779\n",
      "Epoch 59 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.986\n",
      "Epoch 60 --- Training Accuracy:  97.5%, Validation Accuracy:  75.0%, Validation Loss: 0.758\n",
      "Epoch 61 --- Training Accuracy:  87.5%, Validation Accuracy:  52.5%, Validation Loss: 1.280\n",
      "Epoch 62 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 0.745\n",
      "Epoch 63 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 0.932\n",
      "Epoch 64 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 0.623\n",
      "Epoch 65 --- Training Accuracy: 100.0%, Validation Accuracy:  55.0%, Validation Loss: 1.338\n",
      "Epoch 66 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.338\n",
      "Epoch 67 --- Training Accuracy: 100.0%, Validation Accuracy:  50.0%, Validation Loss: 1.519\n",
      "Epoch 68 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.074\n",
      "Epoch 69 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.155\n",
      "Epoch 70 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 0.803\n",
      "Epoch 71 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 0.709\n",
      "Epoch 72 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 0.831\n",
      "Epoch 73 --- Training Accuracy: 100.0%, Validation Accuracy:  60.0%, Validation Loss: 1.139\n",
      "Epoch 74 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 1.341\n",
      "Epoch 75 --- Training Accuracy: 100.0%, Validation Accuracy:  65.0%, Validation Loss: 1.582\n",
      "Epoch 76 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%, Validation Loss: 1.119\n",
      "Epoch 77 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 1.160\n",
      "Epoch 78 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 0.744\n",
      "Epoch 79 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 1.096\n",
      "Epoch 80 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.969\n",
      "Epoch 81 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%, Validation Loss: 1.319\n",
      "Epoch 82 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.589\n",
      "Epoch 83 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.823\n",
      "Epoch 84 --- Training Accuracy: 100.0%, Validation Accuracy:  80.0%, Validation Loss: 0.673\n",
      "Epoch 85 --- Training Accuracy: 100.0%, Validation Accuracy:  65.0%, Validation Loss: 1.396\n",
      "Epoch 86 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 1.285\n",
      "Epoch 87 --- Training Accuracy: 100.0%, Validation Accuracy:  60.0%, Validation Loss: 1.701\n",
      "Epoch 88 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.957\n",
      "Epoch 89 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.332\n",
      "Epoch 90 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 0.905\n",
      "Epoch 91 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 0.735\n",
      "Epoch 92 --- Training Accuracy: 100.0%, Validation Accuracy:  80.0%, Validation Loss: 0.965\n",
      "Epoch 93 --- Training Accuracy: 100.0%, Validation Accuracy:  65.0%, Validation Loss: 1.232\n",
      "Epoch 94 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 1.466\n",
      "Epoch 95 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 1.735\n",
      "Epoch 96 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%, Validation Loss: 1.376\n",
      "Epoch 97 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 1.370\n",
      "Epoch 98 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 0.899\n",
      "Epoch 99 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 1.175\n",
      "Epoch 100 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 1.083\n",
      "Epoch 101 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%, Validation Loss: 1.527\n",
      "Epoch 102 --- Training Accuracy: 100.0%, Validation Accuracy:  80.0%, Validation Loss: 0.532\n",
      "Epoch 103 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.939\n",
      "Epoch 104 --- Training Accuracy: 100.0%, Validation Accuracy:  85.0%, Validation Loss: 0.792\n",
      "Epoch 105 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.522\n",
      "Epoch 106 --- Training Accuracy: 100.0%, Validation Accuracy:  70.0%, Validation Loss: 1.344\n",
      "Epoch 107 --- Training Accuracy: 100.0%, Validation Accuracy:  57.5%, Validation Loss: 2.024\n",
      "Epoch 108 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 1.030\n",
      "Epoch 109 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.484\n",
      "Epoch 110 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 1.089\n",
      "Epoch 111 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 0.920\n",
      "Epoch 112 --- Training Accuracy: 100.0%, Validation Accuracy:  82.5%, Validation Loss: 1.205\n",
      "Epoch 113 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%, Validation Loss: 1.400\n",
      "Epoch 114 --- Training Accuracy: 100.0%, Validation Accuracy:  72.5%, Validation Loss: 1.656\n",
      "Epoch 115 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 1.921\n",
      "Epoch 116 --- Training Accuracy: 100.0%, Validation Accuracy:  62.5%, Validation Loss: 1.832\n",
      "Epoch 117 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.661\n",
      "Epoch 118 --- Training Accuracy: 100.0%, Validation Accuracy:  80.0%, Validation Loss: 1.197\n",
      "Epoch 119 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 1.254\n",
      "Epoch 120 --- Training Accuracy: 100.0%, Validation Accuracy:  77.5%, Validation Loss: 1.240\n",
      "Epoch 121 --- Training Accuracy: 100.0%, Validation Accuracy:  65.0%, Validation Loss: 1.702\n",
      "Epoch 122 --- Training Accuracy: 100.0%, Validation Accuracy:  82.5%, Validation Loss: 0.549\n",
      "Epoch 123 --- Training Accuracy: 100.0%, Validation Accuracy:  75.0%, Validation Loss: 1.040\n",
      "Epoch 124 --- Training Accuracy: 100.0%, Validation Accuracy:  82.5%, Validation Loss: 0.969\n",
      "Epoch 125 --- Training Accuracy: 100.0%, Validation Accuracy:  65.0%, Validation Loss: 1.664\n",
      "Epoch 126 --- Training Accuracy: 100.0%, Validation Accuracy:  67.5%, Validation Loss: 1.412\n",
      "Epoch 127 --- Training Accuracy: 100.0%, Validation Accuracy:  65.0%, Validation Loss: 2.370\n",
      "Epoch 128 --- Training Accuracy: 100.0%, Validation Accuracy:  82.5%, Validation Loss: 1.147\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import urllib\n",
    "import numpy as np\n",
    "import pdb\n",
    "import dataset\n",
    "\n",
    "if sys.version_info[0] >= 3:\n",
    "  from urllib.request import urlretrieve\n",
    "else:\n",
    "  from urllib import urlretrieve\n",
    "\n",
    "LOGDIR = 'skin/'\n",
    "# Number of color channels for the images: 1 channel for gray-scale.\n",
    "num_channels = 3\n",
    "\n",
    "# image dimensions (only squares for now)\n",
    "img_size = 128\n",
    "\n",
    "# Size of image when flattened to a single dimension\n",
    "img_size_flat = img_size * img_size * num_channels\n",
    "\n",
    "# Tuple with height and width of images used to reshape arrays.\n",
    "img_shape = (img_size, img_size)\n",
    "\n",
    "# class info\n",
    "\n",
    "classes = ['benign', 'malignant']\n",
    "num_classes = len(classes)\n",
    "\n",
    "# batch size\n",
    "batch_size = 40\n",
    "train_batch_size = batch_size\n",
    "# validation split\n",
    "validation_size = .3\n",
    "\n",
    "# Add convolution layer\n",
    "def conv_layer(input, size_in, size_out, name=\"conv\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    act = tf.nn.relu(conv + b)\n",
    "    return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "# Add fully connected layer\n",
    "def fc_layer(input, size_in, size_out, name=\"fc\"):\n",
    "  with tf.name_scope(name):\n",
    "    w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W\")\n",
    "    b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B\")\n",
    "    act = tf.matmul(input, w) + b\n",
    "    return act\n",
    "def flatten_layer(layer):\n",
    "    # Get the shape of the input layer.\n",
    "    layer_shape = layer.get_shape()\n",
    "\n",
    "    # The shape of the input layer is assumed to be:\n",
    "    # layer_shape == [num_images, img_height, img_width, num_channels]\n",
    "\n",
    "    # The number of features is: img_height * img_width * num_channels\n",
    "    # We can use a function from TensorFlow to calculate this.\n",
    "    num_features = layer_shape[1:4].num_elements()\n",
    "\n",
    "    # Reshape the layer to [num_images, num_features].\n",
    "    # Note that we just set the size of the second dimension\n",
    "    # to num_features and the size of the first dimension to -1\n",
    "    # which means the size in that dimension is calculated\n",
    "    # so the total size of the tensor is unchanged from the reshaping.\n",
    "    layer_flat = tf.reshape(layer, [-1, num_features])\n",
    "\n",
    "    # The shape of the flattened layer is now:\n",
    "    # [num_images, img_height * img_width * num_channels]\n",
    "\n",
    "    # Return both the flattened layer and the number of features.\n",
    "    return layer_flat, num_features\n",
    "def print_progress(sess,epoch, feed_dict_train, feed_dict_validate, val_loss,accuracy):\n",
    "    # Calculate the accuracy on the training-set.\n",
    "    acc = sess.run(accuracy, feed_dict=feed_dict_train)\n",
    "    val_acc = sess.run(accuracy, feed_dict=feed_dict_validate)\n",
    "    msg = \"Epoch {0} --- Training Accuracy: {1:>6.1%}, Validation Accuracy: {2:>6.1%}, Validation Loss: {3:.3f}\"\n",
    "    print(msg.format(epoch + 1, acc, val_acc, val_loss))\n",
    "\n",
    "def skin_model(learning_rate, use_two_conv, use_two_fc, hparam):\n",
    "  tf.reset_default_graph()\n",
    "  config = tf.ConfigProto()\n",
    "  config.gpu_options.allocator_type = 'BFC'\n",
    "  sess = tf.Session(config = config)\n",
    "\n",
    "  # Setup placeholders, and reshape the data\n",
    "  x = tf.placeholder(tf.float32, shape=[None, 49152], name=\"x\")\n",
    "  x_image = tf.reshape(x, [-1, img_size, img_size, num_channels])\n",
    "  tf.summary.image('input', x_image, 3)\n",
    "  y = tf.placeholder(tf.float32, shape=[None, 2], name=\"labels\")\n",
    "\n",
    "  if use_two_conv:\n",
    "    conv1 = conv_layer(x_image, num_channels, 32, \"conv1\")\n",
    "    conv_out = conv_layer(conv1, 32, 64, \"conv2\")\n",
    "  else:\n",
    "    conv1 = conv_layer(x_image, num_channels, 64, \"conv\")\n",
    "    conv_out = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "  flattened, num_features = flatten_layer(conv_out)\n",
    "\n",
    "\n",
    "  if use_two_fc:\n",
    "    fc1 = fc_layer(flattened, num_features, 128, \"fc1\")\n",
    "    logits = fc_layer(fc1, 128, 2, \"fc2\")\n",
    "    tf.add_to_collection(\"logits\", logits)\n",
    "  else:\n",
    "    logits = fc_layer(flattened, img_size_flat, 2, \"fc\")\n",
    "    tf.add_to_collection(\"logits\", logits)\n",
    "\n",
    "  with tf.name_scope(\"xent\"):\n",
    "    xent = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(\n",
    "            logits=logits, labels=y), name=\"xent\")\n",
    "    xent_summary = tf.summary.scalar(\"xent\", xent)\n",
    "\n",
    "  with tf.name_scope(\"train\"):\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(xent)\n",
    "\n",
    "  with tf.name_scope(\"accuracy\"):\n",
    "    correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    train_summary = tf.summary.scalar(\"train_accuracy\", accuracy)\n",
    "    validate_summary = tf.summary.scalar(\"validate_accuracy\", accuracy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  writer = tf.summary.FileWriter(LOGDIR + hparam)\n",
    "  writer.add_graph(sess.graph)\n",
    "\n",
    "  config = tf.contrib.tensorboard.plugins.projector.ProjectorConfig()\n",
    " \n",
    "  train_path='/home/mati/Documentos/Harvard/bigdata/finalproject/dataset/ISIC-Dataset-Downloader/train_small'\n",
    "\n",
    "  data = dataset.read_train_sets(train_path, img_size, classes, validation_size=validation_size)\n",
    "\n",
    "  print(\"Size of:\")\n",
    "  print(\"- Training-set:\\t\\t{}\".format(len(data.train.labels)))\n",
    "  print(\"- Validation-set:\\t{}\".format(len(data.valid.labels)))\n",
    "\n",
    "\n",
    "  # step 4: Batching\n",
    "  #image_batch = tf.train.batch([resized_image], batch_size=8)\n",
    "  for i in range(6000):\n",
    "    # Get a batch of training examples.\n",
    "    # x_batch now holds a batch of images and\n",
    "    # y_true_batch are the true labels for those images.\n",
    "    x_batch, y_true_batch, _, cls_batch = data.train.next_batch(train_batch_size)\n",
    "    x_valid_batch, y_valid_batch, _, valid_cls_batch = data.valid.next_batch(train_batch_size)\n",
    "       \n",
    "    # Convert shape from [num examples, rows, columns, depth]\n",
    "    # to [num examples, flattened image shape]\n",
    "    x_batch = x_batch.reshape(train_batch_size, img_size_flat)\n",
    "    x_valid_batch = x_valid_batch.reshape(train_batch_size, img_size_flat)\n",
    "    # Put the batch into a dict with the proper names\n",
    "    # for placeholder variables in the TensorFlow graph.\n",
    "    feed_dict_train = {x: x_batch,\n",
    "                           y: y_true_batch}\n",
    "        \n",
    "    feed_dict_validate = {x: x_valid_batch,\n",
    "                              y: y_valid_batch}\n",
    "    if i % 5 == 0:\n",
    "      [train_accuracy,train_sum,xent_sum] = sess.run([accuracy,train_summary,xent_summary], feed_dict=feed_dict_train)\n",
    "      writer.add_summary(train_sum, i)\n",
    "      writer.add_summary(xent_sum, i)\n",
    "    # Print status at end of each epoch (defined as full pass through training dataset).\n",
    "    if i % int(data.train.num_examples/batch_size) == 0: \n",
    "        val_loss = sess.run(xent, feed_dict=feed_dict_validate)\n",
    "        epoch = int(i / int(data.train.num_examples/batch_size))\n",
    "        print_progress(sess,epoch, feed_dict_train, feed_dict_validate, val_loss,accuracy)\n",
    "        [validate_accuracy,validate_sum] = sess.run([accuracy,validate_summary], feed_dict=feed_dict_validate)\n",
    "        writer.add_summary(validate_sum, i)\n",
    "        \n",
    "    sess.run(train_step, feed_dict=feed_dict_train)\n",
    "  model_saver = tf.train.Saver() \n",
    "  # Train the model and save it in the end\n",
    "  model_saver.save(sess, os.path.join(os.getcwd(), 'skin.ckpt'))\n",
    "  model_saver.export_meta_graph(os.path.join(os.getcwd(), 'skin.meta'))  \n",
    "    \n",
    "def make_hparam_string(learning_rate, use_two_fc, use_two_conv):\n",
    "  conv_param = \"conv2\" if use_two_conv else \"conv1\"\n",
    "  fc_param = \"fc2\" if use_two_fc else \"fc1\"\n",
    "  return \"lr_%.0E%s%s\" % (learning_rate, conv_param, fc_param)\n",
    "def main():\n",
    "  # You can try adding some more learning rates\n",
    "  #for learning_rate in [1E-3, 1E-4, 1E-5]:\n",
    "  for learning_rate in [1E-4]:\n",
    "\n",
    "    # Include \"False\" as a value to try different model architectures\n",
    "    #for use_two_fc in [True, False]:\n",
    "    for use_two_fc in [True]:\n",
    "      #for use_two_conv in [True, False]:\n",
    "      for use_two_conv in [True]:\n",
    "        # Construct a hyperparameter string for each one (example: \"lr_1E-3fc2conv2\")\n",
    "        hparam = make_hparam_string(learning_rate, use_two_fc, use_two_conv)\n",
    "        print('Starting run for %s' % hparam)\n",
    "        sys.stdout.flush() # this forces print-ed lines to show up.\n",
    "\n",
    "\t    # Actually run with the new settings\n",
    "        skin_model(learning_rate, use_two_fc, use_two_conv, hparam)\n",
    "\n",
    "\n",
    "if __name__ == '__main__': \n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2 Tensor",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
